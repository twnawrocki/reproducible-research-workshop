---
title: "Reproducible Analyses Workshop"
author: "Timm Nawrocki"
date: "May 17, 2018"
output:
  html_document:
    keep_md: yes
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Set Libraries, include=FALSE}
# Install required libraries if they are not already installed.
Required_Packages <- c("devtools", "dplyr", "DT", "ggplot2", "ggpmisc", "kableExtra", "leaflet", "readxl", "remotes", "tidyr")
New_Packages <- Required_Packages[!(Required_Packages %in% installed.packages()[,"Package"])]
if (length(New_Packages) > 0) {
  install.packages(New_Packages)
}

# Import required libraries.
library(devtools)
library(dplyr)
library(DT)
library(ggplot2)
library(ggpmisc)
library(kableExtra)
library(leaflet)
library(readxl)
library(remotes)
library(tidyr)

# Set seed
set.seed(415)

# Set working directory by user input
userDirectory <- choose.dir()
setwd(userDirectory)
```

## Environment Settings

The environment settings for this session are:

```{r environmentSettings, echo=FALSE}
# Print session info to the markdown document
sessionInfo()
```

## Example Plot

The following code produces an example point plot based on random numbers.

```{r examplePlot}
# Create example plot in the markdown document
ggplot(data.frame(x=rnorm(100), y=rnorm(100)), aes(x,y)) +
  geom_point()
data('mpg')
```

## Example Table

The following code produces an example table using the "mpg" dataset.

```{r datatable}
# Import example dataset and output a table in the markdown document
data('mpg')
datatable(mpg, caption='Mileage')
```

## Tidying data using dplyr and tidyr

```{r readCatch}
# Read in csv from url
catch_data = read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1", method = "libcurl"), stringsAsFactors = FALSE)
```

The pipe function (%>%) takes an initial defined argument and passes it as the first argument in an initial command. For every subsequent command where the pipe is repeated, the output from the last command is input as the first argument in a subsequent command. The final command needs to be stored as a variable.

```{r gatherCatch}
# Select columns for analysis and transpose into a new table shape
catch_data = catch_data %>%
  select(Region, Year, Chinook, Sockeye, Coho, Pink, Chum)

# Gather the data frame and save as a new data frame
catch_gather = gather(catch_data, key = species, value = catch, Chinook, Sockeye, Coho, Pink, Chum)
```

The output table has "gathered" the catch-species columns into a "species" column and a "catch" column. The key specifies the new column name for the column names listed in the arguments and the value specifies the new column name for the values that existed within the columns listed in the arguments.

```{r spreadCatch}
# Spread the gathered data back to its wide form and save as a new data frame
catch_spread = spread(catch_gather, key = species, value = catch, fill = NA)
```

The syntax for spreading the data functions in opposite such that key specifies the column headings to be added and the value parses into those columns.

```{r catchError}
# Add a new field to data frame and multiply by 1000 to correct for units. An error for a non-numeric value in row 401 is corrected by converting to integer.
catch_gather = catch_gather %>% 
  rename(catch_thousands = catch) %>%
  rename(regionCode = Region) %>%
  mutate(catch_thousands = ifelse(catch_thousands == "I", 1, catch_thousands),
         catch_thousands = as.integer(catch_thousands)) %>%
  mutate(catch = catch_thousands * 1000)
```

```{r summaryTables}
# Example summary by species
catch_species = catch_gather %>%
  group_by(species) %>%
  summarize(catch_mean = mean(catch), num_obs = n())

# Example summary for Chinook salmon by year
catch_chinookYear = catch_gather %>%
  filter(species == 'Chinook') %>%
  group_by(Year) %>%
  summarize(catch_mean = mean(catch), num_obs = n()) %>%
  arrange(desc(mean_catch))
```

The next csv to read in to a data frame contains full names that correspond to the region codes. This data frame will allow the addition of the region codes to the gathered catch data frame.

```{r readRegions}
# Read in the region names csv from url
region_names = read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.303.1", method = "libcurl"), stringsAsFactors = FALSE)
```

Joins between data frames in R function similarly to SQL relational databases. For small data projects, data manipulation in R is likely adequate. For large datasets or datasets that require long-term maintenance, SQL is a better data manipulation language.

```{r joinRegions}
# Select and rename fields from the region_names data frame
region_names = region_names %>%
  select(code, mgmtArea) %>%
  rename(region = mgmtArea) %>%
  rename(regionCode = code)

# Perform a left join to add the full region name to the catch_gather data frame
catch_gather = left_join(catch_gather, region_names, by = c('regionCode' = 'regionCode'))
```

## Data Preparation Exercise

```{r dataManipulation}
# Read Andrew and Volk 2017 escapement goals csv into data frame
escapement_goals = read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/knb.92014.1", method = "libcurl"), stringsAsFactors = FALSE)

# Filter escapement goals data frame to Bristol Bay region and sockeye salmon
escapement_goals = filter(escapement_goals, Species == 'Sockeye' & Region == 'Bristol Bay' & Type == 'SEG')

# Change Lower field to numeric in escapement goals
escapement_goals$Lower = as.numeric(escapement_goals$Lower)

# Replace 'eliminated' value in Lower field with NA and change to numeric
escapement_goals = mutate(escapement_goals, Lower = ifelse(Lower == "eliminated", NA, Lower), Lower = as.numeric(Lower))

# Select System, Upper, and Lower fields from escapement_goals
escapement_goals = select(escapement_goals, System, Lower, Upper)

# Read ADF&G 2017 daily escapement counts csv into data frame
daily_escapement = read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/knb.92020.1", method = "libcurl"), stringsAsFactors = FALSE)

# Filter escapement counts data frame to Bristol Bay region and sockeye salmon
daily_escapement = daily_escapement %>%
  rename(Region = SASAP.Region) %>%
  filter(Species == 'Sockeye' & Region == 'Bristol Bay')

# Parse date field to multiple fields 
daily_escapement = separate(daily_escapement, sampleDate, c("year", "month", "day"), "-")

# Calculate annual total escapements for each stock and integrate escapement goal upper and lower and store as new data frame
annual_escapement = daily_escapement %>%
  group_by(year, Location) %>%
  summarize(annualEscapement = sum(DailyCount))

# Perform an inner join between annual_escapement and escapement goals to join the upper and lower bounds to the annual escapement for systems/locations for which SEG escapement goals have been documented
annual_escapement = inner_join(annual_escapement, escapement_goals, by = c('Location' = 'System'))

# Add new field 'goalMet' indicating a boolean for the statement 'The observed escapement was between the upper and lower goal bounds'
annual_escapement$goalMet = annual_escapement$annualEscapement > annual_escapement$Lower & annual_escapement$annualEscapement < annual_escapement$Upper

# Create empty vectors to hold data from loop
percentMet = NULL
stock = NULL

# Loop through unique values of 'Location' field, which represent different stocks, calculate the percent of years for which SEG escapement goals were met, and append calculation value and stock name to vectors
for (i in unique(annual_escapement$Location)) {
  stock_escapement = filter(annual_escapement, Location == i)
  percentMet = append(percentMet, sum(stock_escapement$goalMet)/nrow(stock_escapement))
  stock = append(stock, i)
}

# Create data frame from the loop vectors
percent_met = data.frame(stock, percentMet)